import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._
import org.apache.spark.streaming.dstream._
import org.apache.spark.SparkConf

object StatefulTransformations {

  def updateRunningSum(values:Seq[Long], state:Option[Long]) = Some(state.getOrElse(0L) + values.size)

  def main(args:Array[String]) {
    val conf = new SparkConf
    conf.setMaster("spark://master:7077").setAppName("Stateful_transformations")
    val sc = new SparkContext(conf)
    val ssc = new StreamingContext(sc, Seconds(1))
    val lines = ssc.socketTextStream("172.25.41.66", 7777)
    val windowedLines = lines.window(Seconds(4), Seconds(2))
    val mapLines = lines.map(ele => (ele, 1L))
    val windowCounts = windowedLines.count
    val countByWindowLines = lines.countByWindow(Seconds(4), Seconds(2))
    val reducedLines = lines.reduce(_ + _)

    val updateDStream = mapLines.updateStateByKey(updateRunningSum _)
    val mapLines1 = lines.map(ele => (ele, 1))
    val reducedKeyWindow = mapLines.reduceByKeyAndWindow({ (x, y) => x + y }, { (x, y) => x - y }, Seconds(4), Seconds(2))

    windowedLines.print
    windowCounts.print
    reducedKeyWindow.print
    countByWindowLines.print
    updateDStream.print
    reducedLines.print
    ssc.checkpoint("/home/padma/StreamingCheckPoint/")
    ssc.start
    ssc.awaitTermination
  }


}
