import org.apache.spark.{SparkContext, SparkConf}
import org.apache.spark.mllib.classification.{NaiveBayes,
NaiveBayesModel}
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint

object NaiveBayesSample {

  def main (args:Array[String]): Unit =
  {
    val conf = new SparkConf
    conf.setMaster("spark://master:7077").setAppName ("NaiveBayesSample")
    val sc = new SparkContext(conf)
    val data =
      sc.textFile("hdfs://namenode:9000/datasets/weather.csv")
    val parsedData = data.map{line => val parts = line.split(",")
      val label = if(parts(0)=="overcast") 0.0 else
      if(parts(0)=="rainy") 1.0 else 2.0
      val feature1 = parts(1).toDouble
      val feature2 = parts(2).toDouble
      val feature3 = if(parts(3)=="FALSE") 0.0 else 1.0
      LabeledPoint(label,
        Vectors.dense(Array(feature1,feature2,feature3)))}
    // Split data into training (60%) and test (40%)
    val splits = parsedData.randomSplit(Array(0.6,0.4), seed = 11L)
    val training = splits(0)
    val test = splits(1)
    val model = NaiveBayes.train(training, lambda = 1.0, modelType =
      "multinomial")
    val predictionAndLabel = test.map(p =>
      (model.predict(p.features), p.label))
    val accuracy = 1.0*predictionAndLabel.filter(x => x._1 ==
      x._2).count()/test.count()
    println("Accuracy is..."+accuracy)
    //Save and Load model
    model.save(sc, "hdfs://namenode:9000/models/myNaiveBayesModel")
    val sameModel = NaiveBayesModel.load(sc,
      "hdfs://namenode:9000/models/myNaiveBayesModel")
  }
}
