import org.apache.spark.{SparkContext, SparkConf}
import org.apache.spark.mllib.tree.DecisionTree
import org.apache.spark.mllib.tree.model.DecisionTreeModel
import org.apache.spark.mllib.tree.impurity._
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.tree.configuration.Algo

object DecisionTreeSample {

  def main(args:Array[String])
  {
    val conf = new SparkConf
    conf.setMaster("spark://master:7077")
      .setAppName("DecisionTreeSample")
    val sc = new SparkContext(conf)
    val rawData = sc.textFile("hdfs://namenode:9000/datsets/train_noheader.tsv")
    val records = rawData.map(line => line.split("\t"))
    val data = records.map{record =>
    val trimmed = record.map(_.replaceAll("\"", ""))
    val label = trimmed(record.size-1).toInt
    val features = trimmed.slice(4,record.size-1).map(d =>
    if(d=="?") 0.0 else
    d.toDouble)
    LabeledPoint(label, Vectors.dense(features))}
    val maxTreeDepth = 5
    val dtModel = DecisionTree.train(data, Algo.Classification,
    Entropy, maxTreeDepth)
    val predictions = dtModel.predict(data.map(lp => lp.features))
    predictions.take(5).foreach(println)
    }
}
